name: spark
# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  # Allows you to run this workflow manually from the Actions tab
  repository_dispatch:
    types: [spark]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  spark:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    permissions:
      # Give the default GITHUB_TOKEN write permission to commit and push the
      # added or changed files to the repository.
      contents: write

    steps:
    # Checkout the repository
    - uses: actions/checkout@v4

    # List files in the workspace
    - run: ls -la

    # Set up Python
    - uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    # Set up Java
    - uses: actions/setup-java@v4
      with:
        java-version: '21'
        distribution: temurin

    # Set up Spark
    - uses: vemonet/setup-spark@v1
      with:
        spark-version: '3.5.3'
        hadoop-version: '3'

    # Run Spark version check
    - run: spark-submit --version
    - run: wget -O games_data.csv https://raw.githubusercontent.com/AntonioGH1/kafka/refs/heads/main/games_data.csv
    - run: wget -O app.py https://raw.githubusercontent.com/AntonioGH1/spark-labs/refs/heads/main/steam_games.py
    - run: ls -la
    - run: spark-submit --master local app.py games_data.csv
    - run: ls -la
    #

    ## Download dataset and code
    #- run: wget -O dataset.csv ${{github.event.client_payload.dataseturl}}
    #- run: wget -O app.py ${{github.event.client_payload.codeurl}}

    ## List files again
    #- run: ls -la

    ## Execute the Spark job
    #- run: spark-submit --master local app.py dataset.csv

    ## List files in the results directory
    #- name: Verificar contenido de results/
      #run: ls -la results

    ## Descargar un dataset
    #- name: Descargar dataset
     # run: wget -O dataset.csv https://raw.githubusercontent.com/adsoftsito/bigdata/refs/heads/main/datasets/people.csv

 #   - name: Descargar dataset reto
 #     run: wget -O dataset.csv https://raw.githubusercontent.com/adsoftsito/bigdata/refs/heads/main/datasets/5000_points.txt

 #   # List files again
 #   - run: ls -la

 #   # Ejecutar Spark con el nuevo dataset
  #  - name: Ejecutar Spark
  #    run: spark-submit --master local people.py
  #  - name: Ejecutar reto
   #   run: spark-submit --master local points.py

  #  # Verificar contenido de results
  #  - name: Verificar contenido de results/
  #    run: ls -la results

#
    # Commit y push de resultados
    - name: GIT commit and push docs
      env:
        CI_COMMIT_MESSAGE: save spark results
        CI_COMMIT_AUTHOR: AntonioGH1
      run: |
        git config --global user.name "${{ env.CI_COMMIT_AUTHOR }}"
        git config --global user.email "zs21004480@estudiantes.uv.mx"
        # Forzar inclusión de archivos en results/, incluso si están en .gitignore
        git add -f results/* 
        git add results/video_game_sales
        
        # Verificar si hay cambios antes de hacer commit
        if git diff --cached --quiet; then
          echo "No hay cambios para hacer commit"
        else
          git commit -m "${{ env.CI_COMMIT_MESSAGE }}"
          git push
        fi
